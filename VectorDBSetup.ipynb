{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl2LilHSwHsi"
      },
      "source": [
        "\n",
        "# Objective\n",
        "This notebook demonstrates how to setup Elasticsearch as a vector database (VectorDB) to support LLM functions that can provide an intelligent query layer.\n",
        "\n",
        "\n",
        "- **Elasticsearch as the VectorDB**: Acts as the core search engine, storing and retrieving dense vector embeddings efficiently.\n",
        "- **Search Templates**: Marry index capabilities to query parameters, enabling dynamic query generation and structured search execution.\n",
        "\n",
        "This combination enables a more sophisticated search experience, leveraging both structured and unstructured data retrieval methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLHU06SCNTB"
      },
      "source": [
        "## Elasticsearch Setup\n",
        "\n",
        "You will need an Elasticsearch instance that has an **enterprise** plan entitlement to complete this walk thru. This walk thru was built and tested on Elastic Serverless and Elastic Cloud Hosted 9.0.0 on Azure.\n",
        "\n",
        "- Details on how to create a new Elastic serverless project can be found [here](https://www.elastic.co/docs/solutions/search/serverless-elasticsearch-get-started#elasticsearch-get-started-create-project)\n",
        "\n",
        "- Details on how to create an API key can be found [here](https://www.elastic.co/docs/solutions/search/search-connection-details#create-an-api-key-cloud-self-managed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lgQ6WlGFeK6"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kply8eYngIAL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: elasticsearch in ./.venv/lib/python3.12/site-packages (9.0.1)\n",
            "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.77.0)\n",
            "Requirement already satisfied: streamlit in ./.venv/lib/python3.12/site-packages (1.45.0)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.1.0)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (8.1.7)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.15.1 in ./.venv/lib/python3.12/site-packages (from elasticsearch) (8.17.1)\n",
            "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.12/site-packages (from elasticsearch) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from elasticsearch) (4.13.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.4.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2025.4.26)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in ./.venv/lib/python3.12/site-packages (from streamlit) (2.2.5)\n",
            "Requirement already satisfied: packaging<25,>=20 in ./.venv/lib/python3.12/site-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in ./.venv/lib/python3.12/site-packages (from streamlit) (6.30.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (20.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in ./.venv/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in ./.venv/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in ./.venv/lib/python3.12/site-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./.venv/lib/python3.12/site-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./.venv/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in ./.venv/lib/python3.12/site-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in ./.venv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in ./.venv/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (1.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (9.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil->elasticsearch) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install elasticsearch openai streamlit python-dotenv tqdm ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define imports and load environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wcPv-D6lwHsk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from elasticsearch import Elasticsearch, helpers, TransportError, ConnectionError\n",
        "import requests\n",
        "import requests, json\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWSsNKGOzA8m"
      },
      "source": [
        "## Environment variables\n",
        "Supply elasticsearch serverless cloud ID & API Key\n",
        "\n",
        "### Elastic \n",
        "```\n",
        "ELASTIC_URL\n",
        "ELASTIC_API_KEY\n",
        "```\n",
        "\n",
        "### Azure\n",
        "```\n",
        "AZURE_MAPS_API_KEY\n",
        "GEOCODE_URL\n",
        "\n",
        "AZURE_OPENAI_API_KEY\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME\n",
        "AZURE_OPENAI_API_VERSION\n",
        "AZURE_OPENAI_ENDPOINT\n",
        "```\n",
        "\n",
        "**Details on each secret is defined in** [part 1](https://github.com/elastic/elasticsearch-labs/blob/main/supporting-blog-content/unifying-elastic-vector-database-and-llms-for-intelligent-query/Unifying_Elastic_Vector_Database_and_LLMs_for_Intelligent_Query.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HopEUyFHEevL"
      },
      "source": [
        "## Set local variables and test elasticsearch connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nhte8IFpUMSI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000002', 'cluster_name': '3ca433fdd5e04f76bb4c37a4adf40b57', 'cluster_uuid': 'K6dOxDfVSVKeYjKiqGzgSA', 'version': {'number': '9.0.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '112859b85d50de2a7e63f73c8fc70b99eea24291', 'build_date': '2025-04-08T15:13:46.049795831Z', 'build_snapshot': False, 'lucene_version': '10.1.0', 'minimum_wire_compatibility_version': '8.18.0', 'minimum_index_compatibility_version': '8.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Elasticsearch Configurations\n",
        "# Supply your elasticsearch serverless cloud id and api key\n",
        "ELASTIC_URL = os.getenv('ELASTIC_URL')\n",
        "ELASTIC_API_KEY = os.getenv('ELASTIC_API_KEY')\n",
        "\n",
        "##Do not modify\n",
        "INDEX_NAME = \"properties\"\n",
        "TEMPLATE_ID=\"properties-search-template\"\n",
        "DATA_FILE= \"./properties.jsonl\"\n",
        "INFERENCE_ID=\"e5-endpoint\"\n",
        "MODEL_ID=\".multilingual-e5-small_linux-x86_64\"\n",
        "\n",
        "es = Elasticsearch(ELASTIC_URL, api_key=ELASTIC_API_KEY, request_timeout=300)\n",
        "es.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1PQ9s43CrAV"
      },
      "source": [
        "## Create ML inference endpoint\n",
        "We will create set a number of allocations that supports decent ingest throughput and query latency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5riqxfPe1ZwQ",
        "outputId": "64e1a154-450b-4ae5-c448-a549ba6b9763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text embedding endpoint created successfully: {'inference_id': 'e5-endpoint', 'task_type': 'text_embedding', 'service': 'elasticsearch', 'service_settings': {'num_allocations': 10, 'num_threads': 1, 'model_id': '.multilingual-e5-small_linux-x86_64'}, 'chunking_settings': {'strategy': 'sentence', 'max_chunk_size': 250, 'sentence_overlap': 1}}\n"
          ]
        }
      ],
      "source": [
        "def create_text_embedding_endpoint():\n",
        "    \"\"\"\n",
        "    Creates a new text_embedding endpoint in Elasticsearch with explicit min/max allocations and chunk settings.\n",
        "    \"\"\"\n",
        "    url = f\"{ELASTIC_URL}/_inference/text_embedding/{INFERENCE_ID}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"ApiKey {ELASTIC_API_KEY}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"service\": \"elasticsearch\",\n",
        "        \"service_settings\": {\n",
        "            \"model_id\": MODEL_ID,     \n",
        "            \"num_threads\": 1,        \n",
        "            \"num_allocations\": 10 \n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Make the POST request\n",
        "    response = requests.put(url, headers=headers, json=payload)\n",
        "\n",
        "    # Print the response\n",
        "    if response.status_code == 200:\n",
        "        print(\"Text embedding endpoint created successfully:\", response.json())\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "# Call the function to create the endpoint\n",
        "create_text_embedding_endpoint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPRJ410XJH_y"
      },
      "source": [
        "## Create Elasticsearch index\n",
        "Creating an index for the property data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vsvBDOfb5As6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Index 'properties' created.\n"
          ]
        }
      ],
      "source": [
        "def create_index():\n",
        "    mapping = {\n",
        "      \"mappings\": {\n",
        "        \"dynamic\": \"false\",\n",
        "        \"properties\": {\n",
        "          \"annual-tax\": {\"type\": \"integer\"},\n",
        "          \"full_html\": {\"type\": \"text\", \"index\": False},\n",
        "          \"geo_point\": {\n",
        "            \"properties\": {\n",
        "              \"lat\": {\"type\": \"float\"},\n",
        "              \"lon\": {\"type\": \"float\"}\n",
        "            }\n",
        "          },\n",
        "          \"location\": {\"type\": \"geo_point\"},\n",
        "          \"headings\": {\"type\": \"text\"},\n",
        "          \"home-price\": {\"type\": \"integer\"},\n",
        "          \"id\": {\"type\": \"keyword\"},\n",
        "          \"latitude\": {\"type\": \"float\"},\n",
        "          \"listing-agent-info\": {\"type\": \"text\"},\n",
        "          \"longitude\": {\"type\": \"float\"},\n",
        "          \"maintenance-fee\": {\"type\": \"integer\"},\n",
        "          \"meta_keywords\": {\"type\": \"keyword\"},\n",
        "          \"number-of-bathrooms\": {\"type\": \"float\"},\n",
        "          \"number-of-bedrooms\": {\"type\": \"float\"},\n",
        "          \"property-description\": {\"type\": \"text\", \"copy_to\": [\"property-description_semantic\"]},\n",
        "          \"property-description_semantic\": {\n",
        "            \"type\": \"semantic_text\",\n",
        "            \"inference_id\": INFERENCE_ID\n",
        "          },\n",
        "          \"property-features\": {\"type\": \"text\", \n",
        "                                \"copy_to\": [\"property-features_semantic\"], \n",
        "                                \"fields\": {\"keyword\": {\"type\": \"keyword\"}}},\n",
        "          \"property-features_semantic\": {\n",
        "            \"type\": \"semantic_text\",\n",
        "            \"inference_id\": INFERENCE_ID\n",
        "          },\n",
        "          \"property-status\": {\"type\": \"keyword\"},\n",
        "          \"square-footage\": {\"type\": \"float\"},\n",
        "          \"title\": {\"type\": \"text\"}\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    es.indices.create(index=INDEX_NAME, body=mapping)\n",
        "    print(f\"✅ Index '{INDEX_NAME}' created.\")\n",
        "\n",
        "create_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9XaRgU8zRDy"
      },
      "source": [
        "## Search Template\n",
        "\n",
        "Removes the existing properties-search-template if present and replaces it with an updated version. This ensures the template is always current and correctly structured for search operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CQ2S6XilPNB7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted existing search template: properties-search-template\n",
            "Created search template: properties-search-template\n"
          ]
        }
      ],
      "source": [
        "search_template_content = {\n",
        "    \"script\": {\n",
        "        \"lang\": \"mustache\",\n",
        "        \"source\": \"\"\"{\n",
        "            \"_source\": false,\n",
        "            \"size\": 10,\n",
        "            \"fields\": [\n",
        "                \"title\",\n",
        "                \"annual-tax\",\n",
        "                \"maintenance-fee\",\n",
        "                \"number-of-bathrooms\",\n",
        "                \"number-of-bedrooms\",\n",
        "                \"square-footage\",\n",
        "                \"home-price\",\n",
        "                \"property-features\",\n",
        "                \"property-description\"\n",
        "            ],\n",
        "            \"retriever\": {\n",
        "                \"linear\": {\n",
        "                    \"filter\": {\n",
        "                        \"bool\": {\n",
        "                            \"must\": [\n",
        "                                {{#distance}}{\n",
        "                                    \"geo_distance\": {\n",
        "                                        \"distance\": \"{{distance}}\",\n",
        "                                        \"location\": {\n",
        "                                            \"lat\": {{latitude}},\n",
        "                                            \"lon\": {{longitude}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/distance}}\n",
        "                                {{#bedrooms}}{{#distance}},{{/distance}}{\n",
        "                                    \"range\": {\n",
        "                                        \"number-of-bedrooms\": {\n",
        "                                            \"gte\": {{bedrooms}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/bedrooms}}\n",
        "                                {{#bathrooms}}{{#distance}}{{^bedrooms}},{{/bedrooms}}{{/distance}}{{#bedrooms}},{{/bedrooms}}{\n",
        "                                    \"range\": {\n",
        "                                        \"number-of-bathrooms\": {\n",
        "                                            \"gte\": {{bathrooms}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/bathrooms}}\n",
        "                                {{#tax}},{\n",
        "                                    \"range\": {\n",
        "                                        \"annual-tax\": {\n",
        "                                            \"lte\": {{tax}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/tax}}\n",
        "                                {{#maintenance}},{\n",
        "                                    \"range\": {\n",
        "                                        \"maintenance-fee\": {\n",
        "                                            \"lte\": {{maintenance}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/maintenance}}\n",
        "                                {{#square_footage}},{\n",
        "                                    \"range\": {\n",
        "                                        \"square-footage\": {\n",
        "                                            \"gte\": {{square_footage}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/square_footage}}\n",
        "                                {{#home_price}},{\n",
        "                                    \"range\": {\n",
        "                                        \"home-price\": {\n",
        "                                            \"lte\": {{home_price}}\n",
        "                                        }\n",
        "                                    }\n",
        "                                }{{/home_price}}\n",
        "                            ]\n",
        "                        }\n",
        "                    },\n",
        "                    \"retrievers\": [\n",
        "                        {\n",
        "                            \"retriever\": {\n",
        "                                \"standard\": {\n",
        "                                    \"query\": {\n",
        "                                        \"semantic\": {\n",
        "                                            \"field\": \"property-description_semantic\",\n",
        "                                            \"query\": \"{{query}}\"\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            },\n",
        "                            \"weight\": 0.3,\n",
        "                            \"normalizer\": \"minmax\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"retriever\": {\n",
        "                                \"standard\": {\n",
        "                                    \"query\": {\n",
        "                                        \"semantic\": {\n",
        "                                            \"field\": \"property-features_semantic\",\n",
        "                                            \"query\": \"{{query}}\"\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            },\n",
        "                            \"weight\": 0.3,\n",
        "                            \"normalizer\": \"minmax\"\n",
        "                        }\n",
        "                        {{#features}},\n",
        "                        {\n",
        "                            \"retriever\": {\n",
        "                                \"standard\": {\n",
        "                                    \"query\": {\n",
        "                                        \"terms_set\": {\n",
        "                                            \"property-features.keyword\": {\n",
        "                                                \"terms\": [{{features}}],\n",
        "                                                \"minimum_should_match\": 1\n",
        "                                            }\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            },\n",
        "                            \"weight\": 0.7,\n",
        "                            \"normalizer\": \"minmax\"\n",
        "                        }\n",
        "                        {{/features}}\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\"\"\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def create_search_template(\n",
        "    template_id=TEMPLATE_ID, template_content=search_template_content\n",
        "):\n",
        "    \"\"\"Creates a new search template\"\"\"\n",
        "    try:\n",
        "        es.put_script(id=template_id, body=template_content)\n",
        "        print(f\"Created search template: {template_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating template '{template_id}': {e}\")\n",
        "\n",
        "es.delete_script(id=TEMPLATE_ID)\n",
        "print(f\"Deleted existing search template: {TEMPLATE_ID}\")\n",
        "\n",
        "create_search_template()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aroYqG9QJZkI"
      },
      "source": [
        "## Ingest property data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54bcd38e7fa142d1bf78c8503a45d43d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Overall Progress - properties:   0%|          | 0/10000 [00:00<?, ?records/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_RETRIES = 5\n",
        "INITIAL_DELAY = 1  \n",
        "BACKOFF_FACTOR = 2\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "def bulk_with_retries(es_client, actions, max_retries=MAX_RETRIES):\n",
        "    attempt = 0\n",
        "    delay = INITIAL_DELAY\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            helpers.bulk(es_client, actions)\n",
        "            return\n",
        "        except (TransportError, ConnectionError) as e:\n",
        "            attempt += 1\n",
        "            if attempt >= max_retries:\n",
        "                raise e\n",
        "            print(f\"⚠️  Bulk insert failed on attempt {attempt}, retrying in {delay}s... ({type(e).__name__}: {e})\")\n",
        "            time.sleep(delay)\n",
        "            delay *= BACKOFF_FACTOR\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads data from a JSONL file into an Elasticsearch index in batches.\n",
        "    \"\"\"\n",
        "    with open(DATA_FILE, 'r') as file:\n",
        "        total_lines = sum(1 for _ in file)\n",
        "        file.seek(0)\n",
        "\n",
        "        overall_progress = tqdm(total=total_lines, desc=f\"Overall Progress - {INDEX_NAME}\", unit=\"records\", leave=True)\n",
        "        batch = []\n",
        "\n",
        "        for line in file:\n",
        "            record = json.loads(line.strip())\n",
        "            batch.append({\n",
        "                \"_index\": INDEX_NAME,\n",
        "                \"_source\": record\n",
        "            })\n",
        "            overall_progress.update(1)\n",
        "\n",
        "            if len(batch) == BATCH_SIZE:\n",
        "                bulk_with_retries(es, batch)\n",
        "                batch = []\n",
        "\n",
        "        if batch:\n",
        "            bulk_with_retries(es, batch)\n",
        "\n",
        "        overall_progress.close()\n",
        "\n",
        "load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teardown\n",
        "Deletes all data in indexes and the ML inference endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted existing search template: properties-search-template\n",
            "🗑️ Index 'properties' deleted.\n",
            "Text embedding endpoint deleted successfully: {'acknowledged': True, 'pipelines': [], 'indexes': []}\n"
          ]
        }
      ],
      "source": [
        "confirmation = input(f\"Are you sure you want to delete the index and ml inference endpoint? This cannot be undone\")\n",
        "if confirmation.lower() != 'yes':\n",
        "    print(\"Operation canceled.\")\n",
        "else:\n",
        "    try:\n",
        "        es.delete_script(id=TEMPLATE_ID)\n",
        "        print(f\"Deleted existing search template: {TEMPLATE_ID}\")\n",
        "    except Exception as e:\n",
        "        if \"not_found\" in str(e):\n",
        "            print(f\"Search template '{TEMPLATE_ID}' not found, skipping delete.\")\n",
        "        else:\n",
        "            print(f\"Error deleting template '{TEMPLATE_ID}': {e}\")\n",
        "    if es.indices.exists(index=INDEX_NAME):\n",
        "        es.indices.delete(index=INDEX_NAME)\n",
        "        print(f\"🗑️ Index '{INDEX_NAME}' deleted.\")\n",
        "\n",
        "    url = f\"{ELASTIC_URL}/_inference/text_embedding/{INFERENCE_ID}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"ApiKey {ELASTIC_API_KEY}\"\n",
        "    }\n",
        "\n",
        "    # Make the DELETE request\n",
        "    response = requests.delete(url, headers=headers)\n",
        "\n",
        "    # Print the response\n",
        "    if response.status_code == 200:\n",
        "        print(\"Text embedding endpoint deleted successfully:\", response.json())\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
